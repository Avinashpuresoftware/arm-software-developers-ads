---
title: Measure Machine Learning Inference Performance on Arm servers

description: Learn how to measure machine learning inference performance on Arm servers

minutes_to_complete: 20

who_is_this_for: Learning path for software developers interesed in benchmarking machine learning workloads running on Arm servers.

learning_objectives:
    - Install and run tensorflow on your Arm-based cloud server
    - Use MLPerf Inference benchmark suite, an open-sourced benchmark from MLCommons to test ML performance on your Arm server

prerequisites:
    - An [Arm based instance](/learning-paths/cloud/providers) from an appropriate cloud service provider.

author_primary: Jason Andrews

### Tags
skilllevels: Introductory
subjects: ML
armips:
    - Neoverse
tools:
softwaress:
    - tensorflow
operatingsystems:
    - Linux

### FIXED, DO NOT MODIFY
# ================================================================================
weight: 1                       # _index.md always has weight of 1 to order correctly
layout: "learningpathall"       # All files under learning paths have this same wrapper
learning_path_main_page: "yes"  # This should be surfaced when looking for related content. Only set for _index.md of learning path content.
---
